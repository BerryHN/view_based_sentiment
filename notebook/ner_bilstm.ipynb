{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bi-LSTM for NER \n",
    "\n",
    "使用双端 LSTM 进行命名实体识别。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "导入训练语料，并统计词典大小。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 19739 sentences, vocab_size=31477\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import time\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from dataset import BatchGenerator\n",
    "\n",
    "with open('../data/dataset.pkl', 'rb') as inp:\n",
    "    X = pickle.load(inp)\n",
    "    y = pickle.load(inp)\n",
    "\n",
    "vocab_size = len(set(X.flatten()))\n",
    "print 'There are %d sentences, vocab_size=%d' % (X.shape[0], vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating the bi-lstm model.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "from tensorflow.contrib import rnn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "'''\n",
    "For Chinese word segmentation.\n",
    "'''\n",
    "# ##################### config ######################\n",
    "timestep_size = max_len = 32           # 句子长度\n",
    "input_size = embedding_size = 64       # 字向量长度\n",
    "class_num = 6\n",
    "hidden_size = 128    # 隐含层节点数\n",
    "layer_num = 2        # bi-lstm 层数\n",
    "max_grad_norm = 5.0  # 最大梯度（超过此值的梯度将被裁剪）\n",
    "\n",
    "lr = tf.placeholder(tf.float32)\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "batch_size = tf.placeholder(tf.int32)  # 注意类型必须为 tf.int32\n",
    "model_save_path = '../ckpt/bi-lstm.ckpt'  # 模型保存位置\n",
    "\n",
    "\n",
    "def weight_variable(shape):\n",
    "    \"\"\"Create a weight variable with appropriate initialization.\"\"\"\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "\n",
    "def bias_variable(shape):\n",
    "    \"\"\"Create a bias variable with appropriate initialization.\"\"\"\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "\n",
    "X_inputs = tf.placeholder(tf.int32, [None, timestep_size], name='X_input')\n",
    "y_inputs = tf.placeholder(tf.int32, [None, timestep_size], name='y_input')    \n",
    "\n",
    "def lstm_cell():\n",
    "    cell = rnn.LSTMCell(hidden_size, reuse=tf.get_variable_scope().reuse)\n",
    "    return rnn.DropoutWrapper(cell, output_keep_prob=keep_prob)\n",
    "    \n",
    "def bi_lstm(X_inputs):\n",
    "    \"\"\"build the bi-LSTMs network. Return the y_pred\"\"\"\n",
    "    # ** 0.char embedding\n",
    "    embedding = tf.get_variable(\"embedding\", [vocab_size, embedding_size], dtype=tf.float32)\n",
    "    # X_inputs.shape = [batchsize, timestep_size]  ->  inputs.shape = [batchsize, timestep_size, embedding_size]\n",
    "    inputs = tf.nn.embedding_lookup(embedding, X_inputs)  \n",
    "    \n",
    "    # ** 1.构建前向后向多层 LSTM\n",
    "    cell_fw = rnn.MultiRNNCell([lstm_cell() for _ in range(layer_num)], state_is_tuple=True)\n",
    "    cell_bw = rnn.MultiRNNCell([lstm_cell() for _ in range(layer_num)], state_is_tuple=True)\n",
    "  \n",
    "    # ** 2.初始状态\n",
    "    initial_state_fw = cell_fw.zero_state(batch_size, tf.float32)\n",
    "    initial_state_bw = cell_bw.zero_state(batch_size, tf.float32)  \n",
    "    \n",
    "    # **************************************************************\n",
    "    # ** 把 inputs 处理成 rnn.static_bidirectional_rnn 的要求形式\n",
    "    # ** 文档说明\n",
    "    # inputs: A length T list of inputs, each a tensor of shape\n",
    "    # [batch_size, input_size], or a nested tuple of such elements.\n",
    "    # *************************************************************\n",
    "    # ** 3.bi-lstm 计算（tf封装）  一般采用下面 static_bidirectional_rnn 函数调用。\n",
    "    #   但是为了理解计算的细节，所以把后面的这段代码进行展开自己实现了一遍。\n",
    "    # Unstack to get a list of 'n_steps' tensors of shape (batch_size, n_input)\n",
    "    # inputs.shape = [batchsize, timestep_size, embedding_size]  ->  timestep_size tensor, each_tensor.shape = [batchsize, embedding_size]\n",
    "    inputs = tf.unstack(inputs, timestep_size, 1)\n",
    "    try:\n",
    "        outputs, _, _ = rnn.static_bidirectional_rnn(cell_fw, cell_bw, inputs, \n",
    "                        initial_state_fw = initial_state_fw, initial_state_bw = initial_state_bw, dtype=tf.float32)\n",
    "    except Exception: # Old TensorFlow version only returns outputs not states\n",
    "        outputs = rnn.static_bidirectional_rnn(cell_fw, cell_bw, inputs, \n",
    "                        initial_state_fw = initial_state_fw, initial_state_bw = initial_state_bw, dtype=tf.float32)\n",
    "    output = tf.reshape(tf.concat(outputs, 1), [-1, hidden_size * 2])\n",
    "    softmax_w = weight_variable([hidden_size * 2, class_num]) \n",
    "    softmax_b = bias_variable([class_num]) \n",
    "    logits = tf.matmul(output, softmax_w) + softmax_b\n",
    "    return logits\n",
    "\n",
    "\n",
    "y_pred = bi_lstm(X_inputs)\n",
    "# adding extra statistics to monitor\n",
    "# y_inputs.shape = [batch_size, timestep_size]\n",
    "correct_prediction = tf.equal(tf.cast(tf.argmax(y_pred, 1), tf.int32), tf.reshape(y_inputs, [-1]))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "cost = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(labels = tf.reshape(y_inputs, [-1]), logits = y_pred))\n",
    "\n",
    "# ***** 优化求解 *******\n",
    "# 获取模型的所有参数\n",
    "tvars = tf.trainable_variables()\n",
    "# 获取损失函数对于每个参数的梯度\n",
    "grads, _ = tf.clip_by_global_norm(tf.gradients(cost, tvars), max_grad_norm)\n",
    "# 优化器\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=lr)\n",
    "# 梯度下降计算\n",
    "train_op = optimizer.apply_gradients( zip(grads, tvars),\n",
    "    global_step=tf.contrib.framework.get_or_create_global_step())\n",
    "print 'Finished creating the bi-lstm model.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_num=13819, valid_num=1973, test_num=3947\n"
     ]
    }
   ],
   "source": [
    "# 划分 train, valid=0.1, test=0.2\n",
    "sample_num = X.shape[0]\n",
    "valid_num = int(sample_num * 0.1)\n",
    "test_num = int(sample_num * 0.2)\n",
    "np.random.seed(13)\n",
    "new_index = np.random.permutation(sample_num)\n",
    "X = X[new_index]\n",
    "y = y[new_index]\n",
    "X_valid = X[:valid_num]\n",
    "y_valid = y[:valid_num]\n",
    "X_test = X[valid_num:valid_num+test_num]\n",
    "y_test = y[valid_num:valid_num+test_num]\n",
    "X_train = X[valid_num+test_num:]\n",
    "y_train = y[valid_num+test_num:]\n",
    "print 'train_num=%d, valid_num=%d, test_num=%d' % (X_train.shape[0], X_valid.shape[0], X_test.shape[0])\n",
    "\n",
    "# 构建数据生成器\n",
    "data_train = BatchGenerator(X_train, y_train, shuffle=True)\n",
    "data_valid = BatchGenerator(X_valid, y_valid, shuffle=False)\n",
    "data_test = BatchGenerator(X_test, y_test, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "model_save_path = '../ckpt/no-pretrain/'  # 模型保存位置\n",
    "if not os.path.exists(model_save_path):\n",
    "    os.makedirs(model_save_path)\n",
    "model_save_path = model_save_path + 'bi-lstm.ckpt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1， lr=0.0001\n",
      "\ttraining acc=0.648599, cost=1.17721;  valid acc= 0.706011, cost=0.700313 \n",
      "Epoch training 13819, acc=0.648599, cost=1.17721, speed=9.69942 s/epoch\n",
      "EPOCH 2， lr=0.0001\n",
      "\ttraining acc=0.758853, cost=0.644804;  valid acc= 0.859391, cost=0.468904 \n",
      "Epoch training 13819, acc=0.758853, cost=0.644804, speed=7.43223 s/epoch\n",
      "EPOCH 3， lr=0.0001\n",
      "\ttraining acc=0.868997, cost=0.439429;  valid acc= 0.90126, cost=0.360187 \n",
      "Epoch training 13819, acc=0.868997, cost=0.439429, speed=7.28437 s/epoch\n",
      "EPOCH 4， lr=0.0001\n",
      "\ttraining acc=0.903496, cost=0.358408;  valid acc= 0.922466, cost=0.306259 \n",
      "Epoch training 13819, acc=0.903496, cost=0.358408, speed=7.33952 s/epoch\n",
      "EPOCH 5， lr=0.0001\n",
      "\ttraining acc=0.9191, cost=0.318517;  valid acc= 0.930964, cost=0.279745 \n",
      "Epoch training 13819, acc=0.9191, cost=0.318517, speed=7.63235 s/epoch\n",
      "EPOCH 6， lr=0.0001\n",
      "\ttraining acc=0.929302, cost=0.291086;  valid acc= 0.939095, cost=0.258888 \n",
      "Epoch training 13819, acc=0.929302, cost=0.291086, speed=7.92777 s/epoch\n",
      "EPOCH 7， lr=0.0001\n",
      "\ttraining acc=0.935775, cost=0.271398;  valid acc= 0.942603, cost=0.24489 \n",
      "Epoch training 13819, acc=0.935775, cost=0.271398, speed=8.40909 s/epoch\n",
      "EPOCH 8， lr=0.0001\n",
      "\ttraining acc=0.940608, cost=0.256388;  valid acc= 0.94568, cost=0.230662 \n",
      "Epoch training 13819, acc=0.940608, cost=0.256388, speed=8.09787 s/epoch\n",
      "EPOCH 9， lr=0.0001\n",
      "\ttraining acc=0.944254, cost=0.239653;  valid acc= 0.946413, cost=0.215298 \n",
      "Epoch training 13819, acc=0.944254, cost=0.239653, speed=8.40209 s/epoch\n",
      "EPOCH 10， lr=0.0001\n",
      "\ttraining acc=0.946602, cost=0.220055;  valid acc= 0.948358, cost=0.193178 \n",
      "the save path is  ../ckpt/no-pretrain/bi-lstm.ckpt-10\n",
      "Epoch training 13819, acc=0.946602, cost=0.220055, speed=9.56261 s/epoch\n",
      "EPOCH 11， lr=0.0001\n",
      "\ttraining acc=0.948176, cost=0.193675;  valid acc= 0.949538, cost=0.16051 \n",
      "Epoch training 13819, acc=0.948176, cost=0.193675, speed=8.14149 s/epoch\n",
      "EPOCH 12， lr=9.2e-05\n",
      "\ttraining acc=0.951815, cost=0.158756;  valid acc= 0.956506, cost=0.125378 \n",
      "Epoch training 13819, acc=0.951815, cost=0.158756, speed=8.1723 s/epoch\n",
      "EPOCH 13， lr=8.464e-05\n",
      "\ttraining acc=0.959582, cost=0.129669;  valid acc= 0.968543, cost=0.103962 \n",
      "Epoch training 13819, acc=0.959582, cost=0.129669, speed=8.03552 s/epoch\n",
      "EPOCH 14， lr=7.78688e-05\n",
      "\ttraining acc=0.966242, cost=0.11155;  valid acc= 0.973103, cost=0.0912908 \n",
      "Epoch training 13819, acc=0.966242, cost=0.11155, speed=8.34096 s/epoch\n",
      "EPOCH 15， lr=7.16393e-05\n",
      "\ttraining acc=0.970372, cost=0.0995663;  valid acc= 0.974235, cost=0.0841212 \n",
      "Epoch training 13819, acc=0.970372, cost=0.0995663, speed=8.33238 s/epoch\n",
      "EPOCH 16， lr=6.59082e-05\n",
      "\ttraining acc=0.972779, cost=0.0915554;  valid acc= 0.974379, cost=0.0821108 \n",
      "Epoch training 13819, acc=0.972779, cost=0.0915554, speed=7.93744 s/epoch\n",
      "EPOCH 17， lr=6.06355e-05\n",
      "\ttraining acc=0.974342, cost=0.085701;  valid acc= 0.975702, cost=0.075993 \n",
      "Epoch training 13819, acc=0.974342, cost=0.085701, speed=8.26054 s/epoch\n",
      "EPOCH 18， lr=5.57847e-05\n",
      "\ttraining acc=0.97573, cost=0.0811129;  valid acc= 0.976276, cost=0.0734224 \n",
      "Epoch training 13819, acc=0.97573, cost=0.0811129, speed=8.22163 s/epoch\n",
      "EPOCH 19， lr=5.13219e-05\n",
      "\ttraining acc=0.976501, cost=0.0776015;  valid acc= 0.976754, cost=0.072183 \n",
      "Epoch training 13819, acc=0.976501, cost=0.0776015, speed=8.3733 s/epoch\n",
      "EPOCH 20， lr=4.72161e-05\n",
      "\ttraining acc=0.97721, cost=0.0752338;  valid acc= 0.977249, cost=0.0707133 \n",
      "the save path is  ../ckpt/no-pretrain/bi-lstm.ckpt-20\n",
      "Epoch training 13819, acc=0.97721, cost=0.0752338, speed=9.16408 s/epoch\n",
      "EPOCH 21， lr=4.34388e-05\n",
      "\ttraining acc=0.977815, cost=0.0724544;  valid acc= 0.977727, cost=0.0677532 \n",
      "Epoch training 13819, acc=0.977815, cost=0.0724544, speed=8.67759 s/epoch\n",
      "EPOCH 22， lr=3.99637e-05\n",
      "\ttraining acc=0.978559, cost=0.0706085;  valid acc= 0.977966, cost=0.0666132 \n",
      "Epoch training 13819, acc=0.978559, cost=0.0706085, speed=8.60544 s/epoch\n",
      "EPOCH 23， lr=3.67666e-05\n",
      "\ttraining acc=0.978842, cost=0.0688966;  valid acc= 0.978524, cost=0.0655394 \n",
      "Epoch training 13819, acc=0.978842, cost=0.0688966, speed=8.3198 s/epoch\n",
      "EPOCH 24， lr=3.38253e-05\n",
      "\ttraining acc=0.979216, cost=0.0675764;  valid acc= 0.978891, cost=0.0656847 \n",
      "Epoch training 13819, acc=0.979216, cost=0.0675764, speed=8.30938 s/epoch\n",
      "EPOCH 25， lr=3.11193e-05\n",
      "\ttraining acc=0.979784, cost=0.0660488;  valid acc= 0.979146, cost=0.0646283 \n",
      "Epoch training 13819, acc=0.979784, cost=0.0660488, speed=8.09178 s/epoch\n",
      "EPOCH 26， lr=2.86297e-05\n",
      "\ttraining acc=0.98017, cost=0.0647626;  valid acc= 0.979353, cost=0.0636362 \n",
      "Epoch training 13819, acc=0.98017, cost=0.0647626, speed=8.06603 s/epoch\n",
      "EPOCH 27， lr=2.63394e-05\n",
      "\ttraining acc=0.980396, cost=0.0637337;  valid acc= 0.979624, cost=0.0634257 \n",
      "Epoch training 13819, acc=0.980396, cost=0.0637337, speed=8.3965 s/epoch\n",
      "EPOCH 28， lr=2.42322e-05\n",
      "\ttraining acc=0.980457, cost=0.0630851;  valid acc= 0.979768, cost=0.0623035 \n",
      "Epoch training 13819, acc=0.980457, cost=0.0630851, speed=8.11891 s/epoch\n",
      "EPOCH 29， lr=2.22936e-05\n",
      "\ttraining acc=0.980996, cost=0.0615881;  valid acc= 0.979848, cost=0.0619021 \n",
      "Epoch training 13819, acc=0.980996, cost=0.0615881, speed=8.37489 s/epoch\n",
      "EPOCH 30， lr=2.05101e-05\n",
      "\ttraining acc=0.981133, cost=0.0610361;  valid acc= 0.979975, cost=0.0615784 \n",
      "the save path is  ../ckpt/no-pretrain/bi-lstm.ckpt-30\n",
      "Epoch training 13819, acc=0.981133, cost=0.0610361, speed=9.75006 s/epoch\n",
      "EPOCH 31， lr=1.88693e-05\n",
      "\ttraining acc=0.981156, cost=0.0604214;  valid acc= 0.980342, cost=0.0611937 \n",
      "Epoch training 13819, acc=0.981156, cost=0.0604214, speed=8.41324 s/epoch\n",
      "EPOCH 32， lr=1.73598e-05\n",
      "\ttraining acc=0.981578, cost=0.0597241;  valid acc= 0.980421, cost=0.0609795 \n",
      "Epoch training 13819, acc=0.981578, cost=0.0597241, speed=8.48087 s/epoch\n",
      "EPOCH 33， lr=1.5971e-05\n",
      "\ttraining acc=0.981717, cost=0.0590978;  valid acc= 0.980533, cost=0.0605358 \n",
      "Epoch training 13819, acc=0.981717, cost=0.0590978, speed=8.24771 s/epoch\n",
      "EPOCH 34， lr=1.46933e-05\n",
      "\ttraining acc=0.981877, cost=0.0587036;  valid acc= 0.980661, cost=0.060543 \n",
      "Epoch training 13819, acc=0.981877, cost=0.0587036, speed=8.24253 s/epoch\n",
      "EPOCH 35， lr=1.35179e-05\n",
      "\ttraining acc=0.981874, cost=0.0584398;  valid acc= 0.980852, cost=0.0602808 \n",
      "Epoch training 13819, acc=0.981874, cost=0.0584398, speed=8.13688 s/epoch\n",
      "EPOCH 36， lr=1.24364e-05\n",
      "\ttraining acc=0.982025, cost=0.0578286;  valid acc= 0.980948, cost=0.0601858 \n",
      "Epoch training 13819, acc=0.982025, cost=0.0578286, speed=8.29229 s/epoch\n",
      "EPOCH 37， lr=1.14415e-05\n",
      "\ttraining acc=0.982105, cost=0.057578;  valid acc= 0.981043, cost=0.0599839 \n",
      "Epoch training 13819, acc=0.982105, cost=0.057578, speed=8.3727 s/epoch\n",
      "EPOCH 38， lr=1.05262e-05\n",
      "\ttraining acc=0.982429, cost=0.0573992;  valid acc= 0.981235, cost=0.0599757 \n",
      "Epoch training 13819, acc=0.982429, cost=0.0573992, speed=8.18976 s/epoch\n",
      "EPOCH 39， lr=9.6841e-06\n",
      "\ttraining acc=0.982572, cost=0.0565447;  valid acc= 0.981442, cost=0.0596471 \n",
      "Epoch training 13819, acc=0.982572, cost=0.0565447, speed=8.16825 s/epoch\n",
      "EPOCH 40， lr=8.90937e-06\n",
      "\ttraining acc=0.982666, cost=0.05665;  valid acc= 0.981219, cost=0.0593961 \n",
      "the save path is  ../ckpt/no-pretrain/bi-lstm.ckpt-40\n",
      "Epoch training 13819, acc=0.982666, cost=0.05665, speed=9.61393 s/epoch\n",
      "EPOCH 41， lr=8.19662e-06\n",
      "\ttraining acc=0.982803, cost=0.0561784;  valid acc= 0.981282, cost=0.059367 \n",
      "Epoch training 13819, acc=0.982803, cost=0.0561784, speed=8.10353 s/epoch\n",
      "EPOCH 42， lr=7.54089e-06\n",
      "\ttraining acc=0.982878, cost=0.055866;  valid acc= 0.981394, cost=0.0594075 \n",
      "Epoch training 13819, acc=0.982878, cost=0.055866, speed=8.31114 s/epoch\n",
      "EPOCH 43， lr=6.93762e-06\n",
      "\ttraining acc=0.982924, cost=0.055446;  valid acc= 0.981283, cost=0.0592471 \n",
      "Epoch training 13819, acc=0.982924, cost=0.055446, speed=8.35781 s/epoch\n",
      "EPOCH 44， lr=6.38261e-06\n",
      "\ttraining acc=0.983045, cost=0.055302;  valid acc= 0.981474, cost=0.059076 \n",
      "Epoch training 13819, acc=0.983045, cost=0.055302, speed=8.40279 s/epoch\n",
      "EPOCH 45， lr=5.872e-06\n",
      "\ttraining acc=0.983191, cost=0.0545808;  valid acc= 0.981633, cost=0.0589337 \n",
      "Epoch training 13819, acc=0.983191, cost=0.0545808, speed=8.42858 s/epoch\n",
      "EPOCH 46， lr=5.40224e-06\n",
      "\ttraining acc=0.983163, cost=0.0546442;  valid acc= 0.981554, cost=0.058948 \n",
      "Epoch training 13819, acc=0.983163, cost=0.0546442, speed=8.04806 s/epoch\n",
      "EPOCH 47， lr=4.97006e-06\n",
      "\ttraining acc=0.983204, cost=0.0546044;  valid acc= 0.981633, cost=0.0590478 \n",
      "Epoch training 13819, acc=0.983204, cost=0.0546044, speed=8.52936 s/epoch\n",
      "EPOCH 48， lr=4.57246e-06\n",
      "\ttraining acc=0.983312, cost=0.0542753;  valid acc= 0.981506, cost=0.0588848 \n",
      "Epoch training 13819, acc=0.983312, cost=0.0542753, speed=8.36992 s/epoch\n",
      "EPOCH 49， lr=4.20666e-06\n",
      "\ttraining acc=0.983344, cost=0.0543925;  valid acc= 0.981665, cost=0.0587685 \n",
      "Epoch training 13819, acc=0.983344, cost=0.0543925, speed=8.33809 s/epoch\n",
      "EPOCH 50， lr=3.87013e-06\n",
      "\ttraining acc=0.983236, cost=0.0544042;  valid acc= 0.981649, cost=0.0587342 \n",
      "the save path is  ../ckpt/no-pretrain/bi-lstm.ckpt-50\n",
      "Epoch training 13819, acc=0.983236, cost=0.0544042, speed=9.55426 s/epoch\n",
      "EPOCH 51， lr=3.56052e-06\n",
      "\ttraining acc=0.983554, cost=0.053985;  valid acc= 0.981633, cost=0.0587812 \n",
      "Epoch training 13819, acc=0.983554, cost=0.053985, speed=8.19203 s/epoch\n",
      "EPOCH 52， lr=3.27568e-06\n",
      "\ttraining acc=0.983419, cost=0.0539257;  valid acc= 0.981506, cost=0.0588647 \n",
      "Epoch training 13819, acc=0.983419, cost=0.0539257, speed=8.18886 s/epoch\n",
      "EPOCH 53， lr=3.01362e-06\n",
      "\ttraining acc=0.98343, cost=0.0539284;  valid acc= 0.981713, cost=0.0586779 \n",
      "Epoch training 13819, acc=0.98343, cost=0.0539284, speed=8.18192 s/epoch\n",
      "EPOCH 54， lr=2.77253e-06\n",
      "\ttraining acc=0.983638, cost=0.0536883;  valid acc= 0.981697, cost=0.0586147 \n",
      "Epoch training 13819, acc=0.983638, cost=0.0536883, speed=8.42159 s/epoch\n",
      "EPOCH 55， lr=2.55073e-06\n",
      "\ttraining acc=0.983693, cost=0.0534649;  valid acc= 0.981825, cost=0.0585092 \n",
      "Epoch training 13819, acc=0.983693, cost=0.0534649, speed=8.26664 s/epoch\n",
      "EPOCH 56， lr=2.34667e-06\n",
      "\ttraining acc=0.983533, cost=0.0537758;  valid acc= 0.981745, cost=0.0585381 \n",
      "Epoch training 13819, acc=0.983533, cost=0.0537758, speed=7.48799 s/epoch\n",
      "EPOCH 57， lr=2.15894e-06\n",
      "\ttraining acc=0.98369, cost=0.053474;  valid acc= 0.981697, cost=0.0585189 \n",
      "Epoch training 13819, acc=0.98369, cost=0.053474, speed=7.85725 s/epoch\n",
      "EPOCH 58， lr=1.98622e-06\n",
      "\ttraining acc=0.983581, cost=0.0534036;  valid acc= 0.981745, cost=0.0584687 \n",
      "Epoch training 13819, acc=0.983581, cost=0.0534036, speed=7.69762 s/epoch\n",
      "EPOCH 59， lr=1.82732e-06\n",
      "\ttraining acc=0.98362, cost=0.0535806;  valid acc= 0.981729, cost=0.0584579 \n",
      "Epoch training 13819, acc=0.98362, cost=0.0535806, speed=7.67742 s/epoch\n",
      "EPOCH 60， lr=1.68114e-06\n",
      "\ttraining acc=0.983467, cost=0.0536924;  valid acc= 0.981856, cost=0.0583792 \n",
      "the save path is  ../ckpt/no-pretrain/bi-lstm.ckpt-60\n",
      "Epoch training 13819, acc=0.983467, cost=0.0536924, speed=8.51985 s/epoch\n",
      "**TEST RESULT:\n",
      "**Test 3947, acc=0.979879, cost=0.0688535\n"
     ]
    }
   ],
   "source": [
    "def test_epoch(dataset):\n",
    "    \"\"\"Testing or valid.\"\"\"\n",
    "    _batch_size = 980\n",
    "    fetches = [accuracy, cost]\n",
    "    _y = dataset.y\n",
    "    data_size = _y.shape[0]\n",
    "    batch_num = int(data_size / _batch_size)\n",
    "    start_time = time.time()\n",
    "    _costs = 0.0\n",
    "    _accs = 0.0\n",
    "    for i in xrange(batch_num):\n",
    "        X_batch, y_batch = dataset.next_batch(_batch_size)\n",
    "        feed_dict = {X_inputs:X_batch, y_inputs:y_batch, lr:1e-5, batch_size:_batch_size, keep_prob:1.0}\n",
    "        _acc, _cost = sess.run(fetches, feed_dict)\n",
    "        _accs += _acc\n",
    "        _costs += _cost    \n",
    "    mean_acc= _accs / batch_num     \n",
    "    mean_cost = _costs / batch_num\n",
    "    return mean_acc, mean_cost\n",
    "\n",
    "\n",
    "tr_batch_size = 128\n",
    "decay = 0.92\n",
    "max_epoch = 10\n",
    "max_max_epoch = 60\n",
    "display_num = 1  # 每个 epoch 显示是个结果\n",
    "sess.run(tf.global_variables_initializer())\n",
    "tr_batch_num = int(data_train.y.shape[0] / tr_batch_size)  # 每个 epoch 中包含的 batch 数\n",
    "display_batch = int(tr_batch_num / display_num)  # 每训练 display_batch 之后输出一次\n",
    "saver = tf.train.Saver(max_to_keep=10)  # 最多保存的模型数量\n",
    "for epoch in xrange(max_max_epoch):\n",
    "    _lr = 1e-4\n",
    "    if epoch > max_epoch:\n",
    "        _lr = _lr * ((decay) ** (epoch - max_epoch))\n",
    "    print 'EPOCH %d， lr=%g' % (epoch+1, _lr)\n",
    "    start_time = time.time()\n",
    "    _costs = 0.0\n",
    "    _accs = 0.0\n",
    "    show_accs = 0.0\n",
    "    show_costs = 0.0\n",
    "    for batch in xrange(tr_batch_num): \n",
    "        fetches = [accuracy, cost, train_op]\n",
    "        X_batch, y_batch = data_train.next_batch(tr_batch_size)\n",
    "        feed_dict = {X_inputs:X_batch, y_inputs:y_batch, lr:_lr, batch_size:tr_batch_size, keep_prob:0.5}\n",
    "        _acc, _cost, _ = sess.run(fetches, feed_dict) # the cost is the mean cost of one batch\n",
    "        _accs += _acc\n",
    "        _costs += _cost\n",
    "        show_accs += _acc\n",
    "        show_costs += _cost\n",
    "        if (batch + 1) % display_batch == 0:\n",
    "            valid_acc, valid_cost = test_epoch(data_valid)  # valid\n",
    "            print '\\ttraining acc=%g, cost=%g;  valid acc= %g, cost=%g ' % (show_accs / display_batch,\n",
    "                                                show_costs / display_batch, valid_acc, valid_cost)\n",
    "            show_accs = 0.0\n",
    "            show_costs = 0.0\n",
    "    mean_acc = _accs / tr_batch_num \n",
    "    mean_cost = _costs / tr_batch_num\n",
    "    if (epoch + 1) % 10 == 0:  # 每 3 个 epoch 保存一次模型\n",
    "        save_path = saver.save(sess, model_save_path, global_step=(epoch+1))\n",
    "        print 'the save path is ', save_path\n",
    "#     print '\\ttraining %d, acc=%g, cost=%g ' % (data_train.y.shape[0], mean_acc, mean_cost)\n",
    "    print 'Epoch training %d, acc=%g, cost=%g, speed=%g s/epoch' % (data_train.y.shape[0], mean_acc, mean_cost, time.time()-start_time)        \n",
    "# testing\n",
    "print '**TEST RESULT:'\n",
    "test_acc, test_cost = test_epoch(data_test)\n",
    "print '**Test %d, acc=%g, cost=%g' % (data_test.y.shape[0], test_acc, test_cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 结果预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    72614\n",
       "5    48168\n",
       "1     3216\n",
       "2     1412\n",
       "4      854\n",
       "3       40\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_softmax = sess.run(y_pred, feed_dict={X_inputs:X_test, batch_size:X_test.shape[0], keep_prob:1.0})\n",
    "pre_label = np.argmax(pre_softmax, axis=1)\n",
    "sr_pre = pd.Series(pre_label)\n",
    "sr_pre.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    72593\n",
       "5    47888\n",
       "1     2840\n",
       "4     1339\n",
       "2     1333\n",
       "3      311\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_label = y_test.flatten()\n",
    "sr_label= pd.Series(true_label)\n",
    "sr_label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 混淆矩阵与分类结果分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def my_confusion_matrix(y_true, y_pred):  \n",
    "    from sklearn.metrics import confusion_matrix  \n",
    "    labels = list(set(y_true))  \n",
    "    conf_mat = confusion_matrix(y_true, y_pred, labels = labels)  \n",
    "    print \"confusion_matrix(left labels: y_true, up labels: y_pred):\"  \n",
    "    print \"labels\\t\",  \n",
    "    for i in range(len(labels)):  \n",
    "        print labels[i],\"\\t\",  \n",
    "    print   \n",
    "    for i in range(len(conf_mat)):  \n",
    "        print i,\"\\t\",  \n",
    "        for j in range(len(conf_mat[i])):  \n",
    "            print conf_mat[i][j],'\\t',  \n",
    "        print   \n",
    "    print   \n",
    "\n",
    "def my_classification_report(y_true, y_pred):  \n",
    "    from sklearn.metrics import classification_report  \n",
    "    print \"classification_report(left: labels):\"  \n",
    "    print classification_report(y_true, y_pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion_matrix(left labels: y_true, up labels: y_pred):\n",
      "labels\t0 \t1 \t2 \t3 \t4 \t5 \t\n",
      "0 \t71838 \t248 \t90 \t16 \t100 \t301 \t\n",
      "1 \t170 \t2429 \t99 \t0 \t87 \t55 \t\n",
      "2 \t85 \t133 \t1082 \t0 \t7 \t26 \t\n",
      "3 \t132 \t7 \t121 \t22 \t23 \t6 \t\n",
      "4 \t258 \t398 \t20 \t2 \t637 \t24 \t\n",
      "5 \t131 \t1 \t0 \t0 \t0 \t47756 \t\n",
      "\n"
     ]
    }
   ],
   "source": [
    "my_confusion_matrix(true_label, pre_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_report(left: labels):\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.99      0.99     72593\n",
      "          1       0.76      0.86      0.80      2840\n",
      "          2       0.77      0.81      0.79      1333\n",
      "          3       0.55      0.07      0.13       311\n",
      "          4       0.75      0.48      0.58      1339\n",
      "          5       0.99      1.00      0.99     47888\n",
      "\n",
      "avg / total       0.98      0.98      0.98    126304\n",
      "\n"
     ]
    }
   ],
   "source": [
    "my_classification_report(true_label, pre_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "没有使用预训练的语料，一共才14000句话左右，训练的结果比较糟糕。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
