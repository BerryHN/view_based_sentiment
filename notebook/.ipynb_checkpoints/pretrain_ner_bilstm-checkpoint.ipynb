{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bi-LSTM for NER \n",
    "\n",
    "使用预训练好的词向量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "from gensim.models import KeyedVectors\n",
    "import pickle\n",
    "\n",
    "\n",
    "# 导入预训练好的词向量\n",
    "with open('../data/embedding_data.pkl', 'rb') as inp:\n",
    "    W_embedding = pickle.load(inp)\n",
    "    sr_id2word = pickle.load(inp)\n",
    "    sr_word2id = pickle.load(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating the bi-lstm model.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "from tensorflow.contrib import rnn\n",
    "\n",
    "'''\n",
    "For Chinese word segmentation.\n",
    "'''\n",
    "# ##################### config ######################\n",
    "timestep_size = max_len = 32           # 句子长度\n",
    "vocab_size = 5159    # 样本中不同字的个数+1(padding 0)，根据处理数据的时候得到\n",
    "input_size = embedding_size = 64       # 字向量长度\n",
    "class_num = 6\n",
    "hidden_size = 128    # 隐含层节点数\n",
    "layer_num = 2        # bi-lstm 层数\n",
    "max_grad_norm = 5.0  # 最大梯度（超过此值的梯度将被裁剪）\n",
    "\n",
    "lr = tf.placeholder(tf.float32)\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "batch_size = tf.placeholder(tf.int32)  # 注意类型必须为 tf.int32\n",
    "\n",
    "\n",
    "def weight_variable(shape):\n",
    "    \"\"\"Create a weight variable with appropriate initialization.\"\"\"\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "\n",
    "def bias_variable(shape):\n",
    "    \"\"\"Create a bias variable with appropriate initialization.\"\"\"\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "\n",
    "X_inputs = tf.placeholder(tf.int32, [None, timestep_size], name='X_input')\n",
    "y_inputs = tf.placeholder(tf.int32, [None, timestep_size], name='y_input')    \n",
    "\n",
    "def lstm_cell():\n",
    "    cell = rnn.LSTMCell(hidden_size, reuse=tf.get_variable_scope().reuse)\n",
    "    return rnn.DropoutWrapper(cell, output_keep_prob=keep_prob)\n",
    "    \n",
    "def bi_lstm(X_inputs):\n",
    "    \"\"\"build the bi-LSTMs network. Return the y_pred\"\"\"\n",
    "    # ** 0.char embedding\n",
    "#     embedding = tf.get_variable(\"embedding\", [vocab_size, embedding_size], dtype=tf.float32)\n",
    "    embedding = tf.get_variable(name=\"embedding\", shape=W_embedding.shape, \n",
    "                                initializer=tf.constant_initializer(W_embedding), trainable=False)\n",
    "    # X_inputs.shape = [batchsize, timestep_size]  ->  inputs.shape = [batchsize, timestep_size, embedding_size]\n",
    "    inputs = tf.nn.embedding_lookup(embedding, X_inputs)  \n",
    "    \n",
    "    # ** 1.构建前向后向多层 LSTM\n",
    "    cell_fw = rnn.MultiRNNCell([lstm_cell() for _ in range(layer_num)], state_is_tuple=True)\n",
    "    cell_bw = rnn.MultiRNNCell([lstm_cell() for _ in range(layer_num)], state_is_tuple=True)\n",
    "  \n",
    "    # ** 2.初始状态\n",
    "    initial_state_fw = cell_fw.zero_state(batch_size, tf.float32)\n",
    "    initial_state_bw = cell_bw.zero_state(batch_size, tf.float32)  \n",
    "    \n",
    "    # **************************************************************\n",
    "    # ** 把 inputs 处理成 rnn.static_bidirectional_rnn 的要求形式\n",
    "    # ** 文档说明\n",
    "    # inputs: A length T list of inputs, each a tensor of shape\n",
    "    # [batch_size, input_size], or a nested tuple of such elements.\n",
    "    # *************************************************************\n",
    "    # ** 3.bi-lstm 计算（tf封装）  一般采用下面 static_bidirectional_rnn 函数调用。\n",
    "    #   但是为了理解计算的细节，所以把后面的这段代码进行展开自己实现了一遍。\n",
    "    # Unstack to get a list of 'n_steps' tensors of shape (batch_size, n_input)\n",
    "    # inputs.shape = [batchsize, timestep_size, embedding_size]  ->  timestep_size tensor, each_tensor.shape = [batchsize, embedding_size]\n",
    "    inputs = tf.unstack(inputs, timestep_size, 1)\n",
    "    try:\n",
    "        outputs, _, _ = rnn.static_bidirectional_rnn(cell_fw, cell_bw, inputs, \n",
    "                        initial_state_fw = initial_state_fw, initial_state_bw = initial_state_bw, dtype=tf.float32)\n",
    "    except Exception: # Old TensorFlow version only returns outputs not states\n",
    "        outputs = rnn.static_bidirectional_rnn(cell_fw, cell_bw, inputs, \n",
    "                        initial_state_fw = initial_state_fw, initial_state_bw = initial_state_bw, dtype=tf.float32)\n",
    "    output = tf.reshape(tf.concat(outputs, 1), [-1, hidden_size * 2])\n",
    "    softmax_w = weight_variable([hidden_size * 2, class_num]) \n",
    "    softmax_b = bias_variable([class_num]) \n",
    "    logits = tf.matmul(output, softmax_w) + softmax_b\n",
    "    return logits\n",
    "\n",
    "\n",
    "y_pred = bi_lstm(X_inputs)\n",
    "# adding extra statistics to monitor\n",
    "# y_inputs.shape = [batch_size, timestep_size]\n",
    "correct_prediction = tf.equal(tf.cast(tf.argmax(y_pred, 1), tf.int32), tf.reshape(y_inputs, [-1]))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "cost = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(labels = tf.reshape(y_inputs, [-1]), logits = y_pred))\n",
    "\n",
    "# ***** 优化求解 *******\n",
    "# 获取模型的所有参数\n",
    "tvars = tf.trainable_variables()\n",
    "# 获取损失函数对于每个参数的梯度\n",
    "grads, _ = tf.clip_by_global_norm(tf.gradients(cost, tvars), max_grad_norm)\n",
    "# 优化器\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=lr)\n",
    "# 梯度下降计算\n",
    "train_op = optimizer.apply_gradients( zip(grads, tvars),\n",
    "    global_step=tf.contrib.framework.get_or_create_global_step())\n",
    "print 'Finished creating the bi-lstm model.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from dataset import BatchGenerator\n",
    "\n",
    "with open('../data/dataset.pkl', 'rb') as inp:\n",
    "    X = pickle.load(inp)\n",
    "    y = pickle.load(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_num=13819, valid_num=1973, test_num=3947\n"
     ]
    }
   ],
   "source": [
    "# 划分 train, valid=0.1, test=0.2\n",
    "sample_num = X.shape[0]\n",
    "valid_num = int(sample_num * 0.1)\n",
    "test_num = int(sample_num * 0.2)\n",
    "np.random.seed(13)\n",
    "new_index = np.random.permutation(sample_num)\n",
    "X = X[new_index]\n",
    "y = y[new_index]\n",
    "X_valid = X[:valid_num]\n",
    "y_valid = y[:valid_num]\n",
    "X_test = X[valid_num:valid_num+test_num]\n",
    "y_test = y[valid_num:valid_num+test_num]\n",
    "X_train = X[valid_num+test_num:]\n",
    "y_train = y[valid_num+test_num:]\n",
    "print 'train_num=%d, valid_num=%d, test_num=%d' % (X_train.shape[0], X_valid.shape[0], X_test.shape[0])\n",
    "\n",
    "# 构建数据生成器\n",
    "data_train = BatchGenerator(X_train, y_train, shuffle=True)\n",
    "data_valid = BatchGenerator(X_valid, y_valid, shuffle=False)\n",
    "data_test = BatchGenerator(X_test, y_test, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "model_save_path = '../ckpt/pretrain/'  # 模型保存位置\n",
    "if not os.path.exists(model_save_path):\n",
    "    os.makedirs(model_save_path)\n",
    "model_save_path = model_save_path + 'bi-lstm.ckpt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1， lr=0.0001\n",
      "\ttraining acc=0.890317, cost=0.54758;  valid acc= 0.944819, cost=0.257498 \n",
      "Epoch training 13819, acc=0.890317, cost=0.54758, speed=9.9482 s/epoch\n",
      "EPOCH 2， lr=0.0001\n",
      "\ttraining acc=0.941504, cost=0.260413;  valid acc= 0.94678, cost=0.227145 \n",
      "Epoch training 13819, acc=0.941504, cost=0.260413, speed=8.37079 s/epoch\n",
      "EPOCH 3， lr=0.0001\n",
      "\ttraining acc=0.943473, cost=0.235491;  valid acc= 0.947147, cost=0.205897 \n",
      "Epoch training 13819, acc=0.943473, cost=0.235491, speed=8.12263 s/epoch\n",
      "EPOCH 4， lr=0.0001\n",
      "\ttraining acc=0.944242, cost=0.21233;  valid acc= 0.947545, cost=0.181164 \n",
      "Epoch training 13819, acc=0.944242, cost=0.21233, speed=8.13089 s/epoch\n",
      "EPOCH 5， lr=0.0001\n",
      "\ttraining acc=0.945744, cost=0.184518;  valid acc= 0.949841, cost=0.150531 \n",
      "Epoch training 13819, acc=0.945744, cost=0.184518, speed=8.10326 s/epoch\n",
      "EPOCH 6， lr=0.0001\n",
      "\ttraining acc=0.950862, cost=0.155467;  valid acc= 0.95802, cost=0.123583 \n",
      "Epoch training 13819, acc=0.950862, cost=0.155467, speed=8.19468 s/epoch\n",
      "EPOCH 7， lr=0.0001\n",
      "\ttraining acc=0.956963, cost=0.133925;  valid acc= 0.963776, cost=0.107053 \n",
      "Epoch training 13819, acc=0.956963, cost=0.133925, speed=8.1331 s/epoch\n",
      "EPOCH 8， lr=0.0001\n",
      "\ttraining acc=0.960506, cost=0.120988;  valid acc= 0.96596, cost=0.0974229 \n",
      "Epoch training 13819, acc=0.960506, cost=0.120988, speed=8.25998 s/epoch\n",
      "EPOCH 9， lr=0.0001\n",
      "\ttraining acc=0.962884, cost=0.111771;  valid acc= 0.967571, cost=0.0909936 \n",
      "Epoch training 13819, acc=0.962884, cost=0.111771, speed=8.46213 s/epoch\n",
      "EPOCH 10， lr=0.0001\n",
      "\ttraining acc=0.965412, cost=0.104513;  valid acc= 0.970265, cost=0.0842299 \n",
      "the save path is  ../ckpt/pretrain/bi-lstm.ckpt-10\n",
      "Epoch training 13819, acc=0.965412, cost=0.104513, speed=9.50707 s/epoch\n",
      "EPOCH 11， lr=0.0001\n",
      "\ttraining acc=0.966724, cost=0.0990208;  valid acc= 0.972386, cost=0.0794139 \n",
      "Epoch training 13819, acc=0.966724, cost=0.0990208, speed=8.34606 s/epoch\n",
      "EPOCH 12， lr=9.2e-05\n",
      "\ttraining acc=0.967675, cost=0.0948444;  valid acc= 0.974395, cost=0.0751385 \n",
      "Epoch training 13819, acc=0.967675, cost=0.0948444, speed=8.13853 s/epoch\n",
      "EPOCH 13， lr=8.464e-05\n",
      "\ttraining acc=0.969122, cost=0.090439;  valid acc= 0.975367, cost=0.0719679 \n",
      "Epoch training 13819, acc=0.969122, cost=0.090439, speed=8.40474 s/epoch\n",
      "EPOCH 14， lr=7.78688e-05\n",
      "\ttraining acc=0.970226, cost=0.087705;  valid acc= 0.976021, cost=0.0695081 \n",
      "Epoch training 13819, acc=0.970226, cost=0.087705, speed=8.15552 s/epoch\n",
      "EPOCH 15， lr=7.16393e-05\n",
      "\ttraining acc=0.971055, cost=0.0847945;  valid acc= 0.977185, cost=0.067304 \n",
      "Epoch training 13819, acc=0.971055, cost=0.0847945, speed=8.31369 s/epoch\n",
      "EPOCH 16， lr=6.59082e-05\n",
      "\ttraining acc=0.971819, cost=0.0821398;  valid acc= 0.978205, cost=0.0652054 \n",
      "Epoch training 13819, acc=0.971819, cost=0.0821398, speed=8.32112 s/epoch\n",
      "EPOCH 17， lr=6.06355e-05\n",
      "\ttraining acc=0.972859, cost=0.0798608;  valid acc= 0.978365, cost=0.0641444 \n",
      "Epoch training 13819, acc=0.972859, cost=0.0798608, speed=8.44842 s/epoch\n",
      "EPOCH 18， lr=5.57847e-05\n",
      "\ttraining acc=0.97303, cost=0.0785977;  valid acc= 0.979258, cost=0.0626884 \n",
      "Epoch training 13819, acc=0.97303, cost=0.0785977, speed=8.0957 s/epoch\n",
      "EPOCH 19， lr=5.13219e-05\n",
      "\ttraining acc=0.973558, cost=0.0771813;  valid acc= 0.979003, cost=0.0620983 \n",
      "Epoch training 13819, acc=0.973558, cost=0.0771813, speed=8.07264 s/epoch\n",
      "EPOCH 20， lr=4.72161e-05\n",
      "\ttraining acc=0.973811, cost=0.0760725;  valid acc= 0.979369, cost=0.061271 \n",
      "the save path is  ../ckpt/pretrain/bi-lstm.ckpt-20\n",
      "Epoch training 13819, acc=0.973811, cost=0.0760725, speed=9.56727 s/epoch\n",
      "EPOCH 21， lr=4.34388e-05\n",
      "\ttraining acc=0.974317, cost=0.0752699;  valid acc= 0.979576, cost=0.0604791 \n",
      "Epoch training 13819, acc=0.974317, cost=0.0752699, speed=8.18773 s/epoch\n",
      "EPOCH 22， lr=3.99637e-05\n",
      "\ttraining acc=0.97426, cost=0.0744993;  valid acc= 0.979752, cost=0.0599078 \n",
      "Epoch training 13819, acc=0.97426, cost=0.0744993, speed=8.23189 s/epoch\n",
      "EPOCH 23， lr=3.67666e-05\n",
      "\ttraining acc=0.974701, cost=0.0735729;  valid acc= 0.980453, cost=0.0590764 \n",
      "Epoch training 13819, acc=0.974701, cost=0.0735729, speed=8.35129 s/epoch\n",
      "EPOCH 24， lr=3.38253e-05\n",
      "\ttraining acc=0.97494, cost=0.0729686;  valid acc= 0.980071, cost=0.05864 \n",
      "Epoch training 13819, acc=0.97494, cost=0.0729686, speed=8.27592 s/epoch\n",
      "EPOCH 25， lr=3.11193e-05\n",
      "\ttraining acc=0.975244, cost=0.0719432;  valid acc= 0.980214, cost=0.0581817 \n",
      "Epoch training 13819, acc=0.975244, cost=0.0719432, speed=8.16396 s/epoch\n",
      "EPOCH 26， lr=2.86297e-05\n",
      "\ttraining acc=0.975581, cost=0.0710921;  valid acc= 0.980406, cost=0.0578783 \n",
      "Epoch training 13819, acc=0.975581, cost=0.0710921, speed=8.24916 s/epoch\n",
      "EPOCH 27， lr=2.63394e-05\n",
      "\ttraining acc=0.975529, cost=0.0710602;  valid acc= 0.980469, cost=0.057821 \n",
      "Epoch training 13819, acc=0.975529, cost=0.0710602, speed=8.50681 s/epoch\n",
      "EPOCH 28， lr=2.42322e-05\n",
      "\ttraining acc=0.975568, cost=0.0707318;  valid acc= 0.980533, cost=0.0572869 \n",
      "Epoch training 13819, acc=0.975568, cost=0.0707318, speed=8.30838 s/epoch\n",
      "EPOCH 29， lr=2.22936e-05\n",
      "\ttraining acc=0.975791, cost=0.0700544;  valid acc= 0.980677, cost=0.0569238 \n",
      "Epoch training 13819, acc=0.975791, cost=0.0700544, speed=8.04167 s/epoch\n",
      "EPOCH 30， lr=2.05101e-05\n",
      "\ttraining acc=0.975946, cost=0.0695557;  valid acc= 0.980677, cost=0.0566962 \n",
      "the save path is  ../ckpt/pretrain/bi-lstm.ckpt-30\n",
      "Epoch training 13819, acc=0.975946, cost=0.0695557, speed=9.33279 s/epoch\n",
      "EPOCH 31， lr=1.88693e-05\n",
      "\ttraining acc=0.975876, cost=0.0695896;  valid acc= 0.980884, cost=0.0565597 \n",
      "Epoch training 13819, acc=0.975876, cost=0.0695896, speed=8.20826 s/epoch\n",
      "EPOCH 32， lr=1.73598e-05\n",
      "\ttraining acc=0.976079, cost=0.0692182;  valid acc= 0.980852, cost=0.056452 \n",
      "Epoch training 13819, acc=0.976079, cost=0.0692182, speed=8.08995 s/epoch\n",
      "EPOCH 33， lr=1.5971e-05\n",
      "\ttraining acc=0.976348, cost=0.0685753;  valid acc= 0.980868, cost=0.0562777 \n",
      "Epoch training 13819, acc=0.976348, cost=0.0685753, speed=8.25611 s/epoch\n",
      "EPOCH 34， lr=1.46933e-05\n",
      "\ttraining acc=0.976197, cost=0.0685093;  valid acc= 0.980995, cost=0.0561051 \n",
      "Epoch training 13819, acc=0.976197, cost=0.0685093, speed=8.19661 s/epoch\n",
      "EPOCH 35， lr=1.35179e-05\n",
      "\ttraining acc=0.976462, cost=0.0679295;  valid acc= 0.980772, cost=0.0560213 \n",
      "Epoch training 13819, acc=0.976462, cost=0.0679295, speed=8.23798 s/epoch\n",
      "EPOCH 36， lr=1.24364e-05\n",
      "\ttraining acc=0.976327, cost=0.0682809;  valid acc= 0.980916, cost=0.0559116 \n",
      "Epoch training 13819, acc=0.976327, cost=0.0682809, speed=7.97139 s/epoch\n",
      "EPOCH 37， lr=1.14415e-05\n",
      "\ttraining acc=0.976535, cost=0.067912;  valid acc= 0.980948, cost=0.0558159 \n",
      "Epoch training 13819, acc=0.976535, cost=0.067912, speed=8.12435 s/epoch\n",
      "EPOCH 38， lr=1.05262e-05\n",
      "\ttraining acc=0.976439, cost=0.0677279;  valid acc= 0.981011, cost=0.055639 \n",
      "Epoch training 13819, acc=0.976439, cost=0.0677279, speed=8.24627 s/epoch\n",
      "EPOCH 39， lr=9.6841e-06\n",
      "\ttraining acc=0.976645, cost=0.0673159;  valid acc= 0.980932, cost=0.055516 \n",
      "Epoch training 13819, acc=0.976645, cost=0.0673159, speed=8.22055 s/epoch\n",
      "EPOCH 40， lr=8.90937e-06\n",
      "\ttraining acc=0.977055, cost=0.0671095;  valid acc= 0.981123, cost=0.055472 \n",
      "the save path is  ../ckpt/pretrain/bi-lstm.ckpt-40\n",
      "Epoch training 13819, acc=0.977055, cost=0.0671095, speed=9.63389 s/epoch\n",
      "EPOCH 41， lr=8.19662e-06\n",
      "\ttraining acc=0.976818, cost=0.0670662;  valid acc= 0.981059, cost=0.0554083 \n",
      "Epoch training 13819, acc=0.976818, cost=0.0670662, speed=8.36709 s/epoch\n",
      "EPOCH 42， lr=7.54089e-06\n",
      "\ttraining acc=0.976547, cost=0.067442;  valid acc= 0.981219, cost=0.0553438 \n",
      "Epoch training 13819, acc=0.976547, cost=0.067442, speed=8.32052 s/epoch\n",
      "EPOCH 43， lr=6.93762e-06\n",
      "\ttraining acc=0.976875, cost=0.0669383;  valid acc= 0.981043, cost=0.055305 \n",
      "Epoch training 13819, acc=0.976875, cost=0.0669383, speed=8.17807 s/epoch\n",
      "EPOCH 44， lr=6.38261e-06\n",
      "\ttraining acc=0.976991, cost=0.0664166;  valid acc= 0.980964, cost=0.0552408 \n",
      "Epoch training 13819, acc=0.976991, cost=0.0664166, speed=8.19581 s/epoch\n",
      "EPOCH 45， lr=5.872e-06\n",
      "\ttraining acc=0.976948, cost=0.0666835;  valid acc= 0.981091, cost=0.0551544 \n",
      "Epoch training 13819, acc=0.976948, cost=0.0666835, speed=8.14749 s/epoch\n",
      "EPOCH 46， lr=5.40224e-06\n",
      "\ttraining acc=0.977274, cost=0.0660835;  valid acc= 0.981187, cost=0.0551966 \n",
      "Epoch training 13819, acc=0.977274, cost=0.0660835, speed=8.19449 s/epoch\n",
      "EPOCH 47， lr=4.97006e-06\n",
      "\ttraining acc=0.976934, cost=0.0666919;  valid acc= 0.981027, cost=0.0550372 \n",
      "Epoch training 13819, acc=0.976934, cost=0.0666919, speed=8.17484 s/epoch\n",
      "EPOCH 48， lr=4.57246e-06\n",
      "\ttraining acc=0.976978, cost=0.0665708;  valid acc= 0.981043, cost=0.0550412 \n",
      "Epoch training 13819, acc=0.976978, cost=0.0665708, speed=8.21538 s/epoch\n",
      "EPOCH 49， lr=4.20666e-06\n",
      "\ttraining acc=0.977023, cost=0.0661174;  valid acc= 0.981155, cost=0.0549534 \n",
      "Epoch training 13819, acc=0.977023, cost=0.0661174, speed=8.25744 s/epoch\n",
      "EPOCH 50， lr=3.87013e-06\n",
      "\ttraining acc=0.977156, cost=0.0662056;  valid acc= 0.981187, cost=0.0549897 \n",
      "the save path is  ../ckpt/pretrain/bi-lstm.ckpt-50\n",
      "Epoch training 13819, acc=0.977156, cost=0.0662056, speed=9.38273 s/epoch\n",
      "**TEST RESULT:\n",
      "**Test 3947, acc=0.980135, cost=0.0594792\n"
     ]
    }
   ],
   "source": [
    "def test_epoch(dataset):\n",
    "    \"\"\"Testing or valid.\"\"\"\n",
    "    _batch_size = 980\n",
    "    fetches = [accuracy, cost]\n",
    "    _y = dataset.y\n",
    "    data_size = _y.shape[0]\n",
    "    batch_num = int(data_size / _batch_size)\n",
    "    start_time = time.time()\n",
    "    _costs = 0.0\n",
    "    _accs = 0.0\n",
    "    for i in xrange(batch_num):\n",
    "        X_batch, y_batch = dataset.next_batch(_batch_size)\n",
    "        feed_dict = {X_inputs:X_batch, y_inputs:y_batch, lr:1e-5, batch_size:_batch_size, keep_prob:1.0}\n",
    "        _acc, _cost = sess.run(fetches, feed_dict)\n",
    "        _accs += _acc\n",
    "        _costs += _cost    \n",
    "    mean_acc= _accs / batch_num     \n",
    "    mean_cost = _costs / batch_num\n",
    "    return mean_acc, mean_cost\n",
    "\n",
    "\n",
    "decay = 0.92\n",
    "max_epoch = 10\n",
    "max_max_epoch = 50  # 本例中，50个epoch基本上就收敛了\n",
    "tr_batch_size = 128 \n",
    "display_num = 1  # 每个 epoch 显示是个结果\n",
    "sess.run(tf.global_variables_initializer())\n",
    "tr_batch_num = int(data_train.y.shape[0] / tr_batch_size)  # 每个 epoch 中包含的 batch 数\n",
    "display_batch = int(tr_batch_num / display_num)  # 每训练 display_batch 之后输出一次\n",
    "saver = tf.train.Saver(max_to_keep=10)  # 最多保存的模型数量\n",
    "for epoch in xrange(max_max_epoch):\n",
    "    _lr = 1e-4\n",
    "    if epoch > max_epoch:\n",
    "        _lr = _lr * ((decay) ** (epoch - max_epoch))\n",
    "    print 'EPOCH %d， lr=%g' % (epoch+1, _lr)\n",
    "    start_time = time.time()\n",
    "    _costs = 0.0\n",
    "    _accs = 0.0\n",
    "    show_accs = 0.0\n",
    "    show_costs = 0.0\n",
    "    for batch in xrange(tr_batch_num): \n",
    "        fetches = [accuracy, cost, train_op]\n",
    "        X_batch, y_batch = data_train.next_batch(tr_batch_size)\n",
    "        feed_dict = {X_inputs:X_batch, y_inputs:y_batch, lr:_lr, batch_size:tr_batch_size, keep_prob:0.5}\n",
    "        _acc, _cost, _ = sess.run(fetches, feed_dict) # the cost is the mean cost of one batch\n",
    "        _accs += _acc\n",
    "        _costs += _cost\n",
    "        show_accs += _acc\n",
    "        show_costs += _cost\n",
    "        if (batch + 1) % display_batch == 0:\n",
    "            valid_acc, valid_cost = test_epoch(data_valid)  # valid\n",
    "            print '\\ttraining acc=%g, cost=%g;  valid acc= %g, cost=%g ' % (show_accs / display_batch,\n",
    "                                                show_costs / display_batch, valid_acc, valid_cost)\n",
    "            show_accs = 0.0\n",
    "            show_costs = 0.0\n",
    "    mean_acc = _accs / tr_batch_num \n",
    "    mean_cost = _costs / tr_batch_num\n",
    "    if (epoch + 1) % 10 == 0:  # 每 3 个 epoch 保存一次模型\n",
    "        save_path = saver.save(sess, model_save_path, global_step=(epoch+1))\n",
    "        print 'the save path is ', save_path\n",
    "#     print '\\ttraining %d, acc=%g, cost=%g ' % (data_train.y.shape[0], mean_acc, mean_cost)\n",
    "    print 'Epoch training %d, acc=%g, cost=%g, speed=%g s/epoch' % (data_train.y.shape[0], mean_acc, mean_cost, time.time()-start_time)        \n",
    "# testing\n",
    "print '**TEST RESULT:'\n",
    "test_acc, test_cost = test_epoch(data_test)\n",
    "print '**Test %d, acc=%g, cost=%g' % (data_test.y.shape[0], test_acc, test_cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预测结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    73087\n",
       "5    47732\n",
       "1     2737\n",
       "2     1285\n",
       "4     1214\n",
       "3      249\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_softmax = sess.run(y_pred, feed_dict={X_inputs:X_test, batch_size:X_test.shape[0], keep_prob:1.0})\n",
    "pre_label = np.argmax(pre_softmax, axis=1)\n",
    "sr_pre = pd.Series(pre_label)\n",
    "sr_pre.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    72593\n",
       "5    47888\n",
       "1     2840\n",
       "4     1339\n",
       "2     1333\n",
       "3      311\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_label = y_test.flatten()\n",
    "sr_label= pd.Series(true_label)\n",
    "sr_label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 混淆矩阵与分类结果分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def my_confusion_matrix(y_true, y_pred):  \n",
    "    from sklearn.metrics import confusion_matrix  \n",
    "    labels = list(set(y_true))  \n",
    "    conf_mat = confusion_matrix(y_true, y_pred, labels = labels)  \n",
    "    print \"confusion_matrix(left labels: y_true, up labels: y_pred):\"  \n",
    "    print \"labels\\t\",  \n",
    "    for i in range(len(labels)):  \n",
    "        print labels[i],\"\\t\",  \n",
    "    print   \n",
    "    for i in range(len(conf_mat)):  \n",
    "        print i,\"\\t\",  \n",
    "        for j in range(len(conf_mat[i])):  \n",
    "            print conf_mat[i][j],'\\t',  \n",
    "        print   \n",
    "    print   \n",
    "\n",
    "def my_classification_report(y_true, y_pred):  \n",
    "    from sklearn.metrics import classification_report  \n",
    "    print \"classification_report(left: labels):\"  \n",
    "    print classification_report(y_true, y_pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion_matrix(left labels: y_true, up labels: y_pred):\n",
      "labels\t0 \t1 \t2 \t3 \t4 \t5 \t\n",
      "0 \t71812 \t238 \t84 \t33 \t140 \t286 \t\n",
      "1 \t351 \t2302 \t133 \t5 \t49 \t0 \t\n",
      "2 \t121 \t155 \t1050 \t7 \t0 \t0 \t\n",
      "3 \t76 \t1 \t13 \t192 \t29 \t0 \t\n",
      "4 \t285 \t41 \t5 \t12 \t996 \t0 \t\n",
      "5 \t442 \t0 \t0 \t0 \t0 \t47446 \t\n",
      "\n"
     ]
    }
   ],
   "source": [
    "my_confusion_matrix(true_label, pre_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_report(left: labels):\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.99      0.99     72593\n",
      "          1       0.84      0.81      0.83      2840\n",
      "          2       0.82      0.79      0.80      1333\n",
      "          3       0.77      0.62      0.69       311\n",
      "          4       0.82      0.74      0.78      1339\n",
      "          5       0.99      0.99      0.99     47888\n",
      "\n",
      "avg / total       0.98      0.98      0.98    126304\n",
      "\n"
     ]
    }
   ],
   "source": [
    "my_classification_report(true_label, pre_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 和之前没有使用预训练的词向量相比较，结果要好很多。\n",
    "- 使用预训练词向量在一定程度上解决了数据不均衡的问题。\n",
    "- 填充 UNKNOWN 对分类结果没有太大的影响。从混淆矩阵上看，所有的实体词都没有被分到 UNKNOWN 类。\n",
    "- 尽管在整个训练语料中，样本数量比较小，而且类别非常不均衡。但是最后结果显示还是有较好的识别能力。特别是在单词视角上，准确率达到0.83.但是这还需要进一步改进。如果在后面加上 HMM 模型，实体提取的准确率和召回率恒大程度上依赖于 视角首词（也就是类别 2）的识别性能。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
